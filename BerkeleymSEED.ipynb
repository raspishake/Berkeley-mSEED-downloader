{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coded by G. Petricca (@gmrpetricca)\n",
    "\n",
    "from obspy.clients.fdsn import Client\n",
    "from obspy import UTCDateTime, read_inventory\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# read raw data from excel file and create a dataframe (data from http://www.fdsn.org/networks/detail/AM/)\n",
    "# Raspberry Shake stations refined for the W portion of the USA, in a box approx. 32<lat<49 N and 114<lon<124 W\n",
    "dfs = pd.read_excel('ShakeNetwork2020.xlsx', sheet_name=\"W USA Shake Network 2020\")\n",
    "\n",
    "dfs_quake = pd.read_excel('ShakeNetwork2020.xlsx', sheet_name=\"Earthquake List\")\n",
    "\n",
    "dfs_events = dfs_quake['UTC Date Time'].tolist()\n",
    "\n",
    "for j in range(0, len(dfs_events)):\n",
    "    \n",
    "    # distance from earthquake calculations using Haversine Formula\n",
    "    eqdist = []\n",
    "\n",
    "    lat1 = radians(dfs_quake['Latitude'][j])\n",
    "    lon1 = radians(dfs_quake['Longitude'][j])\n",
    "    \n",
    "    for k in range(0, len(dfs)):\n",
    "\n",
    "        lat2 = radians(dfs['Latitude'][k])\n",
    "        lon2 = radians(dfs['Longitude'][k])\n",
    "\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "\n",
    "        a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "        c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "        \n",
    "        R = 6371.0 # approximate radius of earth in km\n",
    "\n",
    "        distance = R * c\n",
    "\n",
    "        eqdist.append(round(distance,1)) # distance from Earthquake in km\n",
    "        #end distance from earthquake calculations\n",
    "\n",
    "    # add distance from event column\n",
    "    dfs['Distance'] = eqdist\n",
    "\n",
    "    # ask the user for a distance limit and select only the appropriate stations\n",
    "    while True:\n",
    "        try:\n",
    "            limit = int(input(\"\\n\" + \"Please insert a km radius to select only the relevant stations. Leave empty to use all.\")) \n",
    "        except ValueError:\n",
    "            limit = 20000 # dummy value to include every station in the dataframe\n",
    "\n",
    "        dfs_def = dfs.loc[(dfs['Distance'] <= limit)]\n",
    "\n",
    "        if dfs_def.empty == False:\n",
    "            # produce and print out some statistics\n",
    "            stations_number = len(dfs_def['Distance']) \n",
    "\n",
    "            if limit == 20000: \n",
    "                print(\"\\n\" + \"There are \" + str(stations_number) + \" stations whitin the max input range.\" + \"\\n\")\n",
    "            else:\n",
    "                print(\"\\n\" + \"There are \" + str(stations_number) + \" stations whitin the \" + str(limit) + \" km input range.\" + \"\\n\")\n",
    "            break\n",
    "\n",
    "        print(\"\\n\" + \"The Station Count is equal to zero. Please input a greater distance.\")\n",
    "    \n",
    "    # define fdsn client to get data from\n",
    "    # this is just to verify if a station was online or offline near the time of the event\n",
    "    event_time = dfs_events[j]\n",
    "    \n",
    "    client = Client('http://fdsnws.raspberryshakedata.com')\n",
    "    orig_time = UTCDateTime(event_time)\n",
    "    t1 = orig_time - 15\n",
    "    t2 = orig_time + 15\n",
    "\n",
    "    dfs_stations = dfs_def['Station Code'].tolist()\n",
    "    \n",
    "    # parse inventories for each station to list their channels\n",
    "    sta_chan = []\n",
    "    for retry in range (0, len(dfs_stations)):\n",
    "        try:\n",
    "            STATION = dfs_stations[retry]\n",
    "            inv = read_inventory('https://fdsnws.raspberryshakedata.com/fdsnws/station/1/query?network=AM&station=%s&level=resp&format=xml&nodata=404&starttime=%s' % (STATION, str(orig_time)))\n",
    "            net = inv[0]\n",
    "            sta = net[0]\n",
    "            cha = len(sta)\n",
    "            \n",
    "            # append the appropriate channels for each online station\n",
    "            if cha == 4: \n",
    "                sta_chan.append(\"EHZ - ENZ - ENN - ENE\")\n",
    "            elif cha == 3:\n",
    "                sta_chan.append(\"EHZ - EHN - EHE\")\n",
    "            else:\n",
    "                if \"SHZ\" in str(sta):\n",
    "                    sta_chan.append(\"SHZ\")\n",
    "                else: \n",
    "                    sta_chan.append(\"EHZ\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            #print(e) # in case of errors\n",
    "            sta_chan.append(' - ')\n",
    "            pass     \n",
    "    \n",
    "    # create an automatic selector to append the online/offline status of each station in the network\n",
    "    onsta = []\n",
    "    for retry in range (0, len(dfs_stations)):\n",
    "        try:\n",
    "            STATION = dfs_stations[retry]\n",
    "            st = client.get_waveforms(\"AM\", STATION, \"00\", \"*HZ\", starttime=t1, endtime=t2, attach_response=True)\n",
    "            str_st = str(st)\n",
    "            if str_st: \n",
    "                onsta.append('Yes')\n",
    "            else:\n",
    "                onsta.append('No')\n",
    "                pass\n",
    "        except Exception as e:\n",
    "            #print(e) # in case of errors\n",
    "            onsta.append('No')\n",
    "            pass\n",
    "        \n",
    "    # put everything into a final dataframe\n",
    "    dfs_def['Online'] = onsta\n",
    "    dfs_def['Channels'] = sta_chan\n",
    "    \n",
    "    # produce and print out some statistics\n",
    "    total_stations = len(dfs_def['Online'])\n",
    "    online_stations = dfs_def['Online'].str.count(\"Yes\").sum() \n",
    "    \n",
    "    # prepare name of final .csv for each event\n",
    "    file_name = str(event_time).replace('-','').replace(':','').replace('.', '').replace('T', '')\n",
    "    \n",
    "    print(\"For the event @ \" + str(event_time) + \" there were \" + str(online_stations) + \" online stations out of \" + str(total_stations) + \" total stations.\" + \"\\n\")\n",
    "    \n",
    "    # create a folder for each earthquake in the list\n",
    "    path = file_name\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    # save the online stations dataframe to .csv file\n",
    "    dfs_def.to_csv(os.path.join(path,r'Online Stations - ' + file_name + '.csv'))\n",
    "    \n",
    "    # prepare conditions for the mSEED files download\n",
    "    dfs_down = dfs_def.loc[(dfs_def['Online'] != \"No\")]\n",
    "\n",
    "    dfs_shakes = dfs_down['Station Code'].tolist()\n",
    "    \n",
    "    start_time = orig_time - 300\n",
    "    end_time = orig_time + 300\n",
    "    \n",
    "    # download the mSEED files for each available channel of each online station in the range\n",
    "    for count in range(0, len(dfs_down)):\n",
    "        \n",
    "        station = dfs_shakes[count]\n",
    "        \n",
    "        channels = [\"SHZ\",\"EHZ\",\"EHN\",\"EHE\",\"ENZ\",\"ENN\",\"ENE\"]\n",
    "        \n",
    "        for chan in range(0, len(channels)):\n",
    "            channel = channels[chan]\n",
    "            url = \"https://fdsnws.raspberryshakedata.com/fdsnws/dataselect/1/query?net=AM&sta=\" + str(station) + \"&loc=00&cha=\" + str(channel) + \"&start=\" + str(start_time) + \"&end=\" + str(end_time) + \"\"\n",
    "            urllib.request.urlretrieve(url, os.path.join(path, r'' + file_name + '.AM.' + station + '.' + channel + '.mseed'))\n",
    "            \n",
    "    # delete empty files, if there are any\n",
    "    str_directory = path\n",
    "    \n",
    "    list_files = [x for x in os.listdir(str_directory) if x[0]!='.']\n",
    "    \n",
    "    for each_file in list_files:\n",
    "        file_path = '%s/%s' % (str_directory, each_file)\n",
    "        \n",
    "        if os.path.getsize(file_path)==0:\n",
    "            os.remove(file_path)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # conclude program\n",
    "    print(\"Download mSEED Files Complete.\" + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
